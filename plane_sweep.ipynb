{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abdad8f-e7f5-4731-9d9e-ed2d80ae4acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as osp\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "from transforms3d.euler import mat2euler, euler2mat\n",
    "import pyrender\n",
    "import trimesh\n",
    "import cv2\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "from utils import viz_camera_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8345e-d9cc-4b01-8304-3a06da0b2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from dataloader import load_middlebury_data\n",
    "DATA = load_middlebury_data(\"data/templeRing\")\n",
    "# reference: https://vision.middlebury.edu/mview/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e8138b-3657-4c58-a0ef-032ab4037c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_view = DATA[2]\n",
    "neighbor_views = [DATA[i] for i in [0, 1, 3, 4]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7f9d5-eae4-4596-a883-af4b5b1f8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for view in neighbor_views:\n",
    "    assert view['rgb'].shape == ref_view['rgb'].shape  \n",
    "height, width = ref_view['rgb'].shape[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0926896-e69c-45de-a985-77d4bd353ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"reference view\")\n",
    "plt.imshow(ref_view[\"rgb\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a56e61f-d533-4e9a-a80d-acdf8a4c6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, view in enumerate(neighbor_views):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.title(\"neighbor view \" + str(i+1)) \n",
    "    plt.imshow(view[\"rgb\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272b79d-28f3-433a-9f3c-2befd9d1c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## vector of depths to sweep our plane across \n",
    "def get_depths(min_depth, max_depth, num_depths):\n",
    "    depths = np.linspace(min_depth, max_depth, num_depths)\n",
    "    return np.float32(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d5c9f-258e-4e73-8e64-bb11d95c992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = 0.52 \n",
    "max_depth = 0.62 \n",
    "num_depths = 25\n",
    "\n",
    "depths = get_depths(min_depth, max_depth, num_depths)\n",
    "depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a54f26-738c-475e-abc1-c36d4ceda33e",
   "metadata": {},
   "source": [
    "The planes will be swept fronto-parallel to the reference camera, so no\n",
    "reprojection needs to be done for this image.  Simply compute the normalized\n",
    "patches across the entire image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a05e2f-1f8a-49e9-b85d-513fcf26b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import image2patch\n",
    "\n",
    "ref_view_patches = image2patch(ref_view['rgb'].astype(np.float)/255.0, k_size=5) # [h,w,k*k,3]\n",
    "ref_view_patches.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b820ac-ae98-4771-8f8e-24edf50d5c69",
   "metadata": {},
   "source": [
    "We'll sweep a series of planes that are fronto-parallel to the right camera.\n",
    "The image from the left camera is to be projected onto each of these planes,\n",
    "normalized, and then compared to the normalized right image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c7bfa7-017f-4038-9224-4f5df820a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plane_sweep_stereo import backproject_corners, project_points, warp_neighbor_to_ref, zncc_kernel_2D\n",
    "volume = []\n",
    "\n",
    "## for each depth, compute and sum the disparity maps between ref and each neighboring view\n",
    "for depth in tqdm(depths):\n",
    "    zncc = np.zeros((height, width))\n",
    "    for neighbor_view in neighbor_views:\n",
    "\n",
    "        K_ref = ref_view['K']\n",
    "        K_neighbor = neighbor_view['K']\n",
    "        \n",
    "        R_ref = ref_view['R']\n",
    "        t_ref = np.expand_dims(ref_view['T'], axis=1)\n",
    "        Rt_ref = np.hstack((R_ref, t_ref))\n",
    "        \n",
    "        R_neighbor = neighbor_view['R']\n",
    "        t_neighbor = np.expand_dims(neighbor_view['T'], axis=1)\n",
    "        Rt_neighbor = np.hstack((R_neighbor, t_neighbor))\n",
    "\n",
    "        warped_neighbor = warp_neighbor_to_ref(backproject_corners, project_points, depth, neighbor_view['rgb'], K_ref, Rt_ref, K_neighbor, Rt_neighbor)\n",
    "       \n",
    "        # patchify this warped left image.\n",
    "\n",
    "        neighbor_view_patches = image2patch(warped_neighbor.astype(np.float)/255.0, k_size=5)\n",
    "\n",
    "        # Compute the ZNCC score between the reference and neighbor images.\n",
    "        ## summing zncc scores across all neighboring views\n",
    "        zncc += zncc_kernel_2D(ref_view_patches, neighbor_view_patches)\n",
    "        \n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "    volume.append(zncc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310db96a-1cf4-4a0e-b803-e35a7f7cae8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# All of these separate ZNCC layers get stacked together into a volume.\n",
    "volume_np = np.dstack(volume)\n",
    "\n",
    "# We're going to use the simplest algorithm to select a depth layer per pixel --\n",
    "# the argmax across depth labels.\n",
    "vol_argmax = volume_np.argmax(axis=2)\n",
    "\n",
    "# Remap the label IDs back to their associated depth values.\n",
    "depth_map = depths[vol_argmax]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc181d09-d3e2-44b6-9fda-007883595139",
   "metadata": {},
   "source": [
    "# Visualize the cost volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from copy import deepcopy\n",
    "volume_np_viz = deepcopy(volume_np)\n",
    "volume_np_viz =  volume_np_viz -  volume_np_viz.min()\n",
    "volume_np_viz = volume_np_viz  / volume_np_viz.max()\n",
    "frames = [(volume_np_viz[:,:,i]*255).astype(np.uint8) for i in range(volume_np_viz.shape[-1])]\n",
    "imageio.mimsave(\"./volume_np.gif\",frames, fps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c9580",
   "metadata": {},
   "source": [
    "<img src=\"volume_np.gif\" width=\"750\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c035a0db-8a38-42d1-b058-88ca73099a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.title(\"reference view\")\n",
    "plt.imshow(cv2.rotate(ref_view[\"rgb\"], cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"raw depth\")\n",
    "plt.imshow(cv2.rotate(depth_map, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5821bedc-9ecd-413c-85b1-420b81d598bf",
   "metadata": {},
   "source": [
    "### Postprocessing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56b5187-ebd9-451b-b706-c91ab0ea587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plane_sweep_stereo import backproject\n",
    "from two_view_stereo import postprocess\n",
    "xyz_cam = backproject(depth_map, K_ref)\n",
    "\n",
    "mask, pcl_world, pcl_cam, pcl_color = postprocess(\n",
    "    depth_map,\n",
    "    ref_view[\"rgb\"],\n",
    "    xyz_cam,\n",
    "    R_wc=ref_view[\"R\"],\n",
    "    T_wc=ref_view[\"T\"][:,None],\n",
    "    z_near=0.5,\n",
    "    z_far=0.6,\n",
    ")\n",
    "\n",
    "mask = (mask > 0).astype(np.float)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"rgb\")\n",
    "plt.imshow(cv2.rotate(ref_view[\"rgb\"], cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"postproc depth\")\n",
    "plt.imshow(cv2.rotate(depth_map * mask, cv2.ROTATE_90_COUNTERCLOCKWISE), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "import numpy as np\n",
    "\n",
    "def viz_3d_embedded(pcl, color):\n",
    "    plot = k3d.plot(camera_auto_fit=True)\n",
    "    color = color.astype(np.uint8)\n",
    "    color32 = (color[:, 0] * 256**2 + color[:, 1] * 256**1 + color[:, 2] * 256**0).astype(\n",
    "        np.uint32\n",
    "    )\n",
    "    plot += k3d.points(pcl.astype(float), color32, point_size=0.001, shader=\"flat\")\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734d9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_3d_embedded(pcl_world, pcl_color.astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cis580')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "4b2e22fa0dd63fa4be21dd649f66ec9e5b8932d8b7feac1c35af38692e142ae7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
