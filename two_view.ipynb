{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS580 Final Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Two View Stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "from utils import viz_camera_poses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Load Data\n",
    "\n",
    "Note: you can uncomment the `viz_camera_poses([view_i, view_j])` to interactively understand the camera configuration, you will get some coordinates colored R-X, G-Y, B-Z. Press `i` in the interactive pyrender window to show the world coordinate.\n",
    "\n",
    "You will find that in the world frame, for each camera, X+ direction is vertically upward, the Y+ direction towards the right, and the Z+ forward.\n",
    "\n",
    "You will get views that are lying horizontally. In each image, the left-up corner has integer pixel coordinate [u,v] = [0,0]. The first index/row index of the image corresponds to Y or v, and the second index/col index of the image corresponds to X or u."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "from dataloader import load_middlebury_data\n",
    "DATA = load_middlebury_data(\"data/templeRing\")\n",
    "# reference: https://vision.middlebury.edu/mview/\n",
    "\n",
    "view_i, view_j = DATA[0], DATA[3]\n",
    "# viz_camera_poses([view_i, view_j])\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Sample: left view (reference)\")\n",
    "plt.imshow(view_i[\"rgb\"])\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Sample: right view\")\n",
    "plt.imshow(view_j[\"rgb\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Rectify two views\n",
    "\n",
    "<!-- Complete the function `compute_right2left_transformation` and `compute_rectification_R`; we have implemented the calibration `rectify_2view`  for you after you get the `R_irect` -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import (\n",
    "    rectify_2view,\n",
    "    compute_rectification_R,\n",
    "    compute_right2left_transformation,\n",
    ")\n",
    "\n",
    "R_wi, T_wi = view_i[\"R\"], view_i[\"T\"][:, None]  # p_i = R_wi @ p_w + T_wi\n",
    "R_wj, T_wj = view_j[\"R\"], view_j[\"T\"][:, None]  # p_j = R_wj @ p_w + T_wj\n",
    "\n",
    "R_ji, T_ji, B = compute_right2left_transformation(R_wi, T_wi, R_wj, T_wj)\n",
    "assert T_ji[1, 0] > 0, \"here we assume view i should be on the left, not on the right\"\n",
    "\n",
    "R_irect = compute_rectification_R(T_ji)\n",
    "\n",
    "rgb_i_rect, rgb_j_rect, K_i_corr, K_j_corr = rectify_2view(\n",
    "    view_i[\"rgb\"],\n",
    "    view_j[\"rgb\"],\n",
    "    R_irect,\n",
    "    R_irect @ R_ji,\n",
    "    view_i[\"K\"],\n",
    "    view_j[\"K\"],\n",
    "    u_padding=20,\n",
    "    v_padding=20,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"input view i\")\n",
    "plt.imshow(cv2.rotate(view_i[\"rgb\"], cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"input view j\")\n",
    "plt.imshow(cv2.rotate(view_j[\"rgb\"], cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"rect view i\")\n",
    "plt.imshow(cv2.rotate(rgb_i_rect, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"rect view j\")\n",
    "plt.imshow(cv2.rotate(rgb_j_rect, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Compute the disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import image2patch, ssd_kernel\n",
    "\n",
    "assert K_i_corr[1, 1] == K_j_corr[1, 1], \"This hw assumes the same focal Y length\"\n",
    "assert (K_i_corr[0] == K_j_corr[0]).all(), \"This hw assumes the same K on X dim\"\n",
    "assert (\n",
    "    rgb_i_rect.shape == rgb_j_rect.shape\n",
    "), \"This hw makes rectified two views to have the same shape\"\n",
    "\n",
    "h, w = rgb_i_rect.shape[:2]\n",
    "\n",
    "d0 = K_j_corr[1, 2] - K_i_corr[1, 2]\n",
    "\n",
    "patches_i = image2patch(rgb_i_rect.astype(float) / 255.0, 3)  # [h,w,k*k,3]\n",
    "patches_j = image2patch(rgb_j_rect.astype(float) / 255.0, 3)  # [h,w,k*k,3]\n",
    "\n",
    "vi_idx, vj_idx = np.arange(h), np.arange(h)\n",
    "disp_candidates = vi_idx[:, None] - vj_idx[None, :] + d0\n",
    "valid_disp_mask = disp_candidates > 0.0\n",
    "\n",
    "# as an example\n",
    "u = 400\n",
    "\n",
    "buf_i, buf_j = patches_i[:, u], patches_j[:, u]\n",
    "value = ssd_kernel(buf_i, buf_j)  # each row is one pix from left, col is the disparity\n",
    "# Students, why we compute this `_upper` ?\n",
    "_upper = value.max() + 1.0\n",
    "value[~valid_disp_mask] = _upper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "# Viz the  disparity-cost of u=500, v=200 on left view\n",
    "v = 200\n",
    "plt.title(\"Cost-Disparity of one left pixel\")\n",
    "plt.xlabel(\"Disparity\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.plot(disp_candidates[v], value[v])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"The cost map of one left horizon col\")\n",
    "plt.xlabel(\"Disparity\")\n",
    "plt.ylabel(\"left pixel coordinates  v_L\")\n",
    "plt.imshow(value)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do the Left-Right consistency: in above right figure, the vertical axis is the left pixel coordinates and the horizontal axis is the right pixel (disparity). \n",
    "\n",
    "When we find the minimal cost right view pixel for our reference pixel (e.g. find the minimum of the left figure), we only check the best matched right pixel patch, which corresponds to finding the minimum along the horizontal axis of the right cost map. \n",
    "\n",
    "However, the matching from the left to the right and from the right to the left should be consistent.\n",
    "So we should also check the minimum of the vertical axis and see whether this two minimum agree with each other, below is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example for the pixel (u=500,v=300) from the left view\n",
    "v = 300\n",
    "best_matched_right_pixel = value[v].argmin()\n",
    "best_matched_left_pixel = value[:,best_matched_right_pixel].argmin()\n",
    "print(v, best_matched_left_pixel)\n",
    "consistent_flag = best_matched_left_pixel == v\n",
    "print(consistent_flag)\n",
    "\n",
    "# example for the pixel (u=500,v=380) from the left view\n",
    "v = 380\n",
    "best_matched_right_pixel = value[v].argmin()\n",
    "best_matched_left_pixel = value[:,best_matched_right_pixel].argmin()\n",
    "print(v, best_matched_left_pixel)\n",
    "consistent_flag = best_matched_left_pixel == v\n",
    "print(consistent_flag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above example, iterate over all u, complete the function `compute_disparity_map`.\n",
    "\n",
    "Tips: for vectorized operation, you may use `take_along_axis` with `argmin` from numpy, please check the documentation from numpy to understand how to use the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import compute_disparity_map\n",
    "\n",
    "disp_map, consistency_mask = compute_disparity_map(\n",
    "    rgb_i_rect, rgb_j_rect, d0=K_j_corr[1, 2] - K_i_corr[1, 2], k_size=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.rotate(consistency_mask, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.title(\"L-R consistency check mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Compute the depth map and point cloud reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import compute_dep_and_pcl\n",
    "\n",
    "# * 3. compute depth map and filter them\n",
    "dep_map, xyz_cam = compute_dep_and_pcl(disp_map, B, K_i_corr)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"rgb\")\n",
    "plt.imshow(cv2.rotate(rgb_i_rect, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"raw disparity\")\n",
    "plt.imshow(cv2.rotate(disp_map, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"raw depth\")\n",
    "plt.imshow(cv2.rotate(dep_map, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Postprocessing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import postprocess\n",
    "\n",
    "mask, pcl_world, pcl_cam, pcl_color = postprocess(\n",
    "    dep_map,\n",
    "    rgb_i_rect,\n",
    "    xyz_cam,\n",
    "    R_wc=R_irect @ R_wi,\n",
    "    T_wc=R_irect @ T_wi,\n",
    "    consistency_mask=consistency_mask,\n",
    "    z_near=0.5,\n",
    "    z_far=0.6,\n",
    ")\n",
    "\n",
    "mask = (mask > 0).astype(np.float)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"rgb\")\n",
    "plt.imshow(cv2.rotate(rgb_i_rect, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"postproc disparity\")\n",
    "plt.imshow(cv2.rotate(disp_map * mask, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.colorbar()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"postproc depth\")\n",
    "plt.imshow(cv2.rotate(dep_map * mask, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import k3d\n",
    "import numpy as np\n",
    "\n",
    "def viz_3d_embedded(pcl, color):\n",
    "    plot = k3d.plot(camera_auto_fit=True)\n",
    "    color = color.astype(np.uint8)\n",
    "    color32 = (color[:, 0] * 256**2 + color[:, 1] * 256**1 + color[:, 2] * 256**0).astype(\n",
    "        np.uint32\n",
    "    )\n",
    "    plot += k3d.points(pcl.astype(float), color32, point_size=0.001, shader=\"flat\")\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSD Two view reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_3d_embedded(pcl_world, pcl_color.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SAD Two view reconstruction results\n",
    "<!-- ### 1.5 Put things together and try different Similarity -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import two_view ,sad_kernel\n",
    "\n",
    "pcl_sad, pcl_color_sad, disp_map_sad, dep_map_sad = two_view(DATA[0], DATA[2], 5, sad_kernel)\n",
    "viz_3d_embedded(pcl_sad, pcl_color_sad.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ZNCC Two view reconstruction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import two_view, zncc_kernel\n",
    "\n",
    "pcl_zncc, pcl_color_zncc, disp_map_zncc, dep_map_zncc = two_view(DATA[0], DATA[2], 5, zncc_kernel)\n",
    "viz_3d_embedded(pcl_zncc, pcl_color_zncc.astype(np.uint8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from two_view_stereo import two_view, ssd_kernel, sad_kernel, zncc_kernel\n",
    "\n",
    "pcl_list, pcl_color_list, disp_map_list, dep_map_list = [], [], [], []\n",
    "pairs = [(0, 2), (2, 4), (5, 7), (8, 10), (13, 15), (16, 18), (19, 21), (22, 24), (25, 27)]\n",
    "# for i in range(13, 28, 3):\n",
    "for pair in pairs:\n",
    "    i,j = pair\n",
    "    _pcl, _pcl_color, _disp_map, _dep_map = two_view(DATA[i], DATA[j], 5, sad_kernel)\n",
    "    pcl_list.append(_pcl)\n",
    "    pcl_color_list.append(_pcl_color)\n",
    "    disp_map_list.append(_disp_map)\n",
    "    dep_map_list.append(_dep_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = k3d.plot(camera_auto_fit=True)\n",
    "for pcl, color in zip(pcl_list, pcl_color_list):\n",
    "    color = color.astype(np.uint8)\n",
    "    color32 = (color[:, 0] * 256**2 + color[:, 1] * 256**1 + color[:, 2] * 256**0).astype(\n",
    "        np.uint32\n",
    "    )\n",
    "    plot += k3d.points(pcl.astype(float), color32, point_size=0.001, shader=\"flat\")\n",
    "plot.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
